{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import lzma\n",
    "import pickle\n",
    "import json\n",
    "import os.path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "import numba as nb\n",
    "nb_u1 = nb.types.uint8\n",
    "nb_u2 = nb.types.uint16\n",
    "\n",
    "from bson.binary import Binary\n",
    "import pymongo\n",
    "\n",
    "sys.path.append(r'C:\\Users\\hornu\\OneDrive\\Documents\\repos\\flags\\scripts\\image-scripts')\n",
    "from image_scaler_cleaner import ImageScalerCleaner\n",
    "from histo_utils import calculate_colour_histogram\n",
    "from image_utils import ImageEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A concise document based database is designed and created for the flags of the countries across the globe in which textual, numeric and image data are stored.\n",
    "\n",
    "\n",
    "## Motivation\n",
    "\n",
    "We have embarked on a journey to learn more about flags and what they represent. In the previous post we preprocessed the images which store the graphical representations. In this one we proceed one step forward in the data analysis pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database design\n",
    "\n",
    "### Current data structure\n",
    "\n",
    "The database, `flags` as it stands now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'config', 'flags', 'local']\n"
     ]
    }
   ],
   "source": [
    "mg_client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "print(mg_client.list_database_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consists of a single collection, `raw_countries`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['countries', 'flags', 'raw_countries']\n"
     ]
    }
   ],
   "source": [
    "db_flag = mg_client[\"flags\"]\n",
    "print(db_flag.list_collection_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in which each document lists the attributes of a particular country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5cb36bfb351ab0806078f97b'),\n",
       " 'adapted': 2004,\n",
       " 'path': 'C:\\\\Users\\\\hornu\\\\OneDrive\\\\Documents\\\\repos\\\\flags\\\\data\\\\clean-data\\\\images\\\\png\\\\afghanistan.png',\n",
       " 'code': 'AF',\n",
       " 'religion': 'ISLAM',\n",
       " 'continent': 'ASIA',\n",
       " 'founded': 1919,\n",
       " 'independent': 1823,\n",
       " 'neighbours': ['CN', 'IR', 'PK', 'TJ', 'TM', 'UZ'],\n",
       " 'name': 'AFGHANISTAN'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_raw_countries = db_flag[\"raw_countries\"]\n",
    "cl_raw_countries.find_one({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fields are either pertaining to the country itself:\n",
    "\n",
    "* `name` : name of the country\n",
    "* `code` : two-letter iso code of the country\n",
    "* `founded` : year in which the country or its ancestor was founded. 9999 stands for missing datum.\n",
    "* `independent` : year in which the country became independent\n",
    "* `religion` : predominant religion in the country\n",
    "* `continent` : continent on which the major landmass of the country situated\n",
    "* `neighbours` : the two letter iso codes of its neighbours\n",
    "\n",
    "or to its flag:\n",
    "* `adapted` : year in which the current flag was introduced\n",
    "* `path` : path to the `png` image of the flag in local store\n",
    "\n",
    "### Design goals\n",
    "\n",
    "We wish to store these pieces of information in a more orderly fashion. The fields relevant to the country should be contained in a document separated from those relevant to the flag itself. Two collections will thus be created: \n",
    "\n",
    "* `countries` and\n",
    "* `flags`\n",
    "\n",
    "#### Country document\n",
    "\n",
    "A country document will have three main fields\n",
    "* `_id` : unique id\n",
    "* `code` : two-letter iso code of the country\n",
    "* `flag` : id of the associated flag document\n",
    "* `data` : all other fields\n",
    "    * `name` : name of the country\n",
    "    * `founded` :  ...\n",
    "    * `independent` : ...\n",
    "    * `adapted` : ...\n",
    "    * `continent` : ...\n",
    "    * `religion` : ...\n",
    "    * `neighbours` : ...\n",
    "    \n",
    "    \n",
    "The country codes of the `neighbours` list will be replaced by the list of the `_id`-s of the respective country documents. This implies the collection must be built in two passes.\n",
    "\n",
    "#### Flag document\n",
    "\n",
    "The flags are stored in a different collection. The schema of a document is the following:\n",
    "\n",
    "* `_id` : unique id\n",
    "* `code` : two letter country code\n",
    "* `data` : information on the flag\n",
    "    * `colours` : a dictionary in which the flag's constituent colours are listed along with their weights\n",
    "    * `dimensions` : a dictionary of height and width\n",
    "    * `canvas` : the flag itself\n",
    " \n",
    "We wish to keep this document as sleek as possible. Therefore only the canvas, some precomputed statitics and the human readable country codes are included in it.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "We set out to implement all the transformations that are required to create the new database.\n",
    "\n",
    "### Flags\n",
    "\n",
    "The main issue is to find an efficient format for storing the canvas of the flag. We went at [great length](https://bhornung.github.io/python/2019/04/09/flags-1.html) to rid the flag of spurious colours, therefore any lossy compression is out of question. \n",
    "\n",
    "#### Copressing the flag\n",
    "\n",
    "The cleaned image is a 3D `uint8` numpy array.  Let us assume an average flag has $500 \\cot 1000$ pixels. Each pixel consists of three meaningful channels (R, G, B). It is then represented in the memory as an array of of size $500 \\cdot 1000 \\cdot 3 = 1.5 \\cdot 10^{6}$ This corresponds to 1.5MBs per image. We wish to make our objects as small as possible so that they travel through the network and memory quickly.\n",
    "\n",
    "There are multiple paths to achieve this:\n",
    "* `numpy` array $\\rightarrow$ pickled object $\\rightarrow$ `lzma`-ed object $\\rightarrow$ Binary field in mongodb\n",
    "* `numpy` array $\\rightarrow$ compressed/modified `numpy` array $\\rightarrow$ pickled object $\\rightarrow$ Binary field in `mongodb`\n",
    "* `numpy` array $\\rightarrow$ compressed/modified `numpy` array $\\rightarrow$ pickled object $\\rightarrow$ `lzma`-ed object $\\rightarrow$ Binary field in `mongodb`\n",
    "\n",
    "In the first route, the pickled array is compressed. These images compress really well, for there are many similar byte sequences corresponding to identical colours. The drawback is that the image has to be manipulated by `lzma` which can be slow.\n",
    "\n",
    "Following the second path, one modifies the numpy array to an other one of considerably smaller size whilst retaining all the spatial information. This array is then pickled. In this case the unpickled object can be used by numpy straightaway. The drawback that the custom compressor/decompressor has to be used, and the user has to be warned accordingly.\n",
    "\n",
    "The third one might be a slow overkill. \n",
    "\n",
    "A minimalistic compressor--decompressor pair is implemented below. `compress_image2` looks for horizontal sequences of indetical colours. (Notwithstanding there is much room for improvement, we choose not delve too deep into optimising these utilities at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython = True)\n",
    "def compress_image2(X):\n",
    "    \"\"\"\n",
    "    Creates a coordinate sparse array representation of an RGB image.\n",
    "    Parameters:\n",
    "        X (np.ndarray[height, width, 3] of uint8) : RGB image.\n",
    "        \n",
    "    Returns:\n",
    "        compressed (np.ndarray[n_regions, 7]) : compressed image, where\n",
    "            row[0:4] : row start, column start, row end, column end\n",
    "            row[4:] : R, G, B codes of the region of constant colour. \n",
    "    \"\"\"\n",
    "    \n",
    "    ir, jr, _ = X.shape\n",
    "    coo = []\n",
    "    \n",
    "    r_s, c_s = 0, 0\n",
    "    c_old = X[0, 0]\n",
    "    \n",
    "    for i in range(ir):\n",
    "        \n",
    "        for j in range(0, jr):\n",
    "            \n",
    "            # append end of color region and colour\n",
    "            if X[i, j, 0] != c_old[0] or \\\n",
    "               X[i, j, 1] != c_old[1] or \\\n",
    "               X[i, j, 2] != c_old[2]:\n",
    "                \n",
    "                if j == 0:\n",
    "                    coo.append([r_s, c_s, i - 1, jr, c_old[0], c_old[1], c_old[2]])\n",
    "                    \n",
    "                else:\n",
    "                    coo.append([r_s, c_s, i, j, c_old[0], c_old[1], c_old[2]])\n",
    "                    \n",
    "                c_old = X[i, j]\n",
    "                r_s, c_s = i, j\n",
    "        \n",
    "    coo.append([r_s, c_s, ir - 1, jr, c_old[0], c_old[1], c_old[2]])\n",
    "    \n",
    "    compressed = np.array(coo, dtype = np.uint16)\n",
    "    \n",
    "    return compressed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decompressor, `decompress_image2` fills subsequent regions with colours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython = True)\n",
    "def decompress_image2(X):\n",
    "    \"\"\"\n",
    "    Creates a coordinate sparse array representation of an RGB image.\n",
    "    \n",
    "    Parameters:\n",
    "        X (np.ndarray[n_regions, 7]) : compressed image, where\n",
    "            row[0:4] : row start, column start, row end, column end\n",
    "            row[4:] : R, G, B codes of the region of constant colour.\n",
    "    Returns:\n",
    "        decompressed (np.ndarray[height, width, 3] of uint8) : RGB image.\n",
    "    \"\"\"\n",
    "    \n",
    "    h = np.int64(X[-1, 2] + 1)\n",
    "    v = np.int64(X[-1, 3])\n",
    "    \n",
    "    decompressed = np.zeros((h, v, 3), dtype = np.uint8)\n",
    "    \n",
    "    for k in range(X.shape[0]):\n",
    "        \n",
    "        r_s = X[k,0]\n",
    "        c_s = X[k,1]\n",
    "        r_e = X[k,2]\n",
    "        c_e = X[k,3]\n",
    "        \n",
    "        if r_s == r_e:\n",
    "            decompressed[r_s, c_s : c_e] = X[k, 4:]\n",
    "            \n",
    "        elif r_s + 1 == r_e:\n",
    "            decompressed[r_s, c_s :] = X[k, 4:]\n",
    "            decompressed[r_e, : c_e] = X[k, 4:]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            decompressed[r_s, c_s :] = X[k, 4:]\n",
    "            decompressed[r_s + 1 : r_e, :] = X[k, 4:]\n",
    "            decompressed[r_e, : c_e] = X[k, 4:]\n",
    "\n",
    "    return decompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO SKIP -- boring\n",
    "\n",
    "# choose specified number of random images\n",
    "#path_to_image_dir = r'C:\\Users\\hornu\\OneDrive\\Documents\\repos\\flags\\data\\clean-data\\images\\png'\n",
    "#paths = np.array([os.path.join(path_to_image_dir, x) for x in os.listdir(path_to_image_dir)])\n",
    "\n",
    "#n_sel = 50\n",
    "#idcs_sel = np.random.choice(len(paths), n_sel, replace = False)\n",
    "\n",
    "#images = [ImageScalerCleaner().clean(imread(paths[idx])) for idx in idcs_sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO SKIP -- boring\n",
    "\n",
    "#ratios_1 = np.zeros(n_sel, dtype = np.float32)\n",
    "#times_1 = np.zeros(n_sel, dtype = np.float32)\n",
    "#\n",
    "#for idx, image in enumerate(images):\n",
    "#    \n",
    "#    # times\n",
    "#    t_start = time.perf_counter()\n",
    "#    compressed_dump = lzma.compress(pickle.dumps(image))\n",
    "#    recon = pickle.loads(lzma.decompress(compressed_dump))\n",
    "#    t_end = time.perf_counter()\n",
    "#    \n",
    "#    times_1[idx] = t_end - t_start\n",
    "#    \n",
    "#    # compression ratio\n",
    "#    ratios_1[idx] = len(compressed_dump) / (image.size * 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO SKIP -- boring\n",
    "\n",
    "#ratios_2 = np.zeros(n_sel, dtype = np.float32)\n",
    "#times_2 = np.zeros(n_sel, dtype = np.float32)\n",
    "#\n",
    "#for idx, image in enumerate(images):\n",
    "#    \n",
    "#    # times\n",
    "#    t_start = time.perf_counter()\n",
    "#    compressed_dump = pickle.dumps(compress_image2(image))\n",
    "#    recon = decompress_image2(pickle.loads(compressed_dump))\n",
    "#    t_end = time.perf_counter()\n",
    "#    \n",
    "#    times_2[idx] = t_end - t_start\n",
    "#    \n",
    "#    # compression ratio\n",
    "#    ratios_2[idx] = len(compressed_dump) / (image.size * 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compression ratios and execution times are compared on a randomly selected set of fifty images. The execution time includes \n",
    "* pickling\n",
    "* compression\n",
    "* extraction\n",
    "* unpickling\n",
    "for both routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO SKIP -- plot setup\n",
    "\n",
    "#fig, axes = plt.subplots(1, 2, gridspec_kw = {\"wspace\" : 0.35})\n",
    "#fig.set_size_inches(10, 5)\n",
    "#\n",
    "#axes[0].grid(True); axes[1].grid(True)\n",
    "#axes[0].set_ylim((0,100)); axes[1].set_ylim((0,0.02));\n",
    "#axes[0].set_ylabel(r'$r_{np} / r_{lzma}$'); axes[1].set_ylabel(r'$t_{np} / t_{lzma}$');\n",
    "#\n",
    "#box_plot = axes[0].boxplot(ratios_2 /ratios_1, labels=[''], patch_artist=True, medianprops=dict(linewidth=2, color='black'))\n",
    "#box_plot['boxes'][0].set_facecolor('cornflowerblue')\n",
    "#        \n",
    "#box_plot = axes[1].boxplot(times_2 /times_1, labels=[''], patch_artist=True, medianprops=dict(linewidth=2, color='black'))\n",
    "#box_plot['boxes'][0].set_facecolor('navy')\n",
    "#\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `lzma` achieves ten to fifteen times better compression ratio, for it has a global view of the bytes that encode the object. The compactness incurrs a high cost in time. It is hundred times slower than the full `numpy` cycle. The rough average timings are 100 ms and 1 ms per image _via_ the `lmza` and `numpy` paths, respectively.\n",
    "\n",
    "As to which one to use, depends on the query time as a function the size of the compressed and pickled object.\n",
    "\n",
    "#### Flag data structure\n",
    "\n",
    "The following steps should be executed to obtain a json template of the \"flag\" document:\n",
    "\n",
    "1. choose relavant fields from raw country documents\n",
    "2. load image from local store\n",
    "3. clean image \n",
    "4. compress and pickle canvas\n",
    "5. generate other statistics fields\n",
    "6. collate to a dictionary\n",
    "\n",
    "Steps 1.--4. are done by the modestly interesting function `create_flag_object_dict` which is shown in its full g(l)ory below. The `ImageScalerCleaner` removes spurious colours due to finite resolution from a flag. Its construction and characteristics were discussed in [this blog post](https://bhornung.github.io/python/2019/04/09/flags-1.html) the source code can be located in [this folder](https://github.com/bhornung/bhornung.github.io/blob/master/assets/flags-1/scripts/image_scripts/image_scaler_cleaner.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flag_document_dict(path, code):\n",
    "    \"\"\"\n",
    "    Reads, cleans compresses a flag and collates with other relevant attributes.\n",
    "    Parameters:\n",
    "        path (str) : local path to the image\n",
    "        code (str) : two letter country code\n",
    "    \n",
    "    Returns:\n",
    "        document_dict ({:}) : dictionary of flag attributes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # create flag bytestring\n",
    "    image = imread(path)\n",
    "    image_bytes = Binary(pickle.dumps(compress_image2(image)))\n",
    "    \n",
    "    # get dimensions\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # get colour histogram\n",
    "    encoded = ImageEncoder.encode(image)\n",
    "    histo = calculate_colour_histogram(encoded)\n",
    "    stringify = lambda x: \"-\".join([str(y) for y in x])\n",
    "    colours = {stringify(colour) : weight \n",
    "                       for colour, weight in zip(histo.colours, histo.counts)}\n",
    "    \n",
    "    data = {\n",
    "             \"canvas\" : image_bytes,\n",
    "             \"dimensions\" : {\"height\" : height, \"width\" : width},\n",
    "             \"colours\" : colours\n",
    "            }\n",
    "        \n",
    "    # collate to all fields\n",
    "    document_dict = {\n",
    "                    \"code\" : code,\n",
    "                    \"data\" : data\n",
    "                  }\n",
    "    \n",
    "    return document_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country document\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fields of the country document are populated from the query result. The `flag` field is omitted, for it will be added once the ids of the flag documents are known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_country_document_dict(fields):\n",
    "    \"\"\"\n",
    "    Creates a dictionary representing a flag document\n",
    "    Parameters:\n",
    "        fields ({:}) : raw country attributes as a dictionary\n",
    "        \n",
    "    Returns:\n",
    "        document_dict ({:}) : dictionary containing the relevant attributes of a certain country\n",
    "    \"\"\"\n",
    "    \n",
    "    # copy accross relevant fields\n",
    "    data_field_names = ('name', 'continent', 'adapted', 'founded', 'independent', 'neighbours', 'religion')\n",
    "    data = {field_name : fields[field_name] for field_name in data_field_names}\n",
    "    \n",
    "    document_dict = {\n",
    "                    \"code\" : fields['code'],\n",
    "                    'data' : data,\n",
    "                    }\n",
    "    \n",
    "    return document_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the collections\n",
    "\n",
    "### Flags\n",
    "\n",
    "All flag dictionaries are created in a single pass over the returned elements from querying the `raw_countries` collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_raw_countries = db_flag[\"raw_countries\"]\n",
    "flag_dicts = [create_flag_document_dict(x['path'], x['code']) for x in cl_raw_countries.find({})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these items the `flags` collection is created. If there is an earlier version it will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1d001023fc8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'flags' in db_flag.list_collection_names():\n",
    "    db_flag.drop_collection('flags')\n",
    "    \n",
    "cl_flag = db_flag.create_collection('flags')\n",
    "cl_flag.insert_many(flag_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a test, we retrieve the flag of Algeria. As expected, there is only one matching document.(Please note, the bytestring is truncated.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code : DZ\n",
      "data : colours : {'255-255-255': 0.4769744855967078, '0-98-51': 0.4601119341563786, '210-16-52': 0.06291358024691358}\n",
      "data : dimensions : {'height': 450, 'width': 675}\n",
      "data : canvas :  b'\\x80\\x03cnumpy.core.multiarray\\n_reconstruct\\nq\\x00cnumpy\\nndarray\\nq\\x01K\\x00\\x85q\\x02C\\x01bq\\x03\\x87q\\x04Rq\\x05(K\\x01M\\x96\\x06K\\x07\\x86q\\x06cnumpy\\ndtype\\nq\\x07X'\n"
     ]
    }
   ],
   "source": [
    "flags = cl_flag.find({'code' : 'DZ'})\n",
    "for flag in flags:\n",
    "    print('code :', flag['code'])\n",
    "    print('data : colours :', flag['data']['colours'])\n",
    "    print('data : dimensions :', flag['data']['dimensions'])\n",
    "    print('data : canvas : ', flag['data']['canvas'][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we print all flags whose canvases contain pure red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5cb36c42351ab0b070ec80d2'), 'code': 'AL'}\n",
      "{'_id': ObjectId('5cb36c42351ab0b070ec80f9'), 'code': 'HR'}\n",
      "{'_id': ObjectId('5cb36c42351ab0b070ec8101'), 'code': 'DO'}\n",
      "{'_id': ObjectId('5cb36c42351ab0b070ec8104'), 'code': 'SV'}\n",
      "{'_id': ObjectId('5cb36c42351ab0b070ec810e'), 'code': 'GE'}\n",
      "{'_id': ObjectId('5cb36c42351ab0b070ec811c'), 'code': 'ID'}\n",
      "{'_id': ObjectId('5cb36c42351ab0b070ec8129'), 'code': 'KG'}\n",
      "{'_id': ObjectId('5cb36c42351ab0b070ec814b'), 'code': 'NI'}\n",
      "{'_id': ObjectId('5cb36c42351ab0b070ec8159'), 'code': 'PT'}\n",
      "{'_id': ObjectId('5cb36c42351ab0b070ec8178'), 'code': 'CH'}\n",
      "{'_id': ObjectId('5cb36c42351ab0b070ec8188'), 'code': 'AE'}\n",
      "{'_id': ObjectId('5cb36c42351ab0b070ec818e'), 'code': 'VA'}\n"
     ]
    }
   ],
   "source": [
    "for flag in cl_flag.find({'data.colours.255-0-0' : {'$exists' : True} }, {'code' : 1}):\n",
    "    print(flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries\n",
    "\n",
    "A list of dictionaries are created from the query on the raw countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dicts = [create_country_document_dict(x) for x in cl_raw_countries.find({})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection of countries is built in three passes:\n",
    "1. The prepared dictionries are inserted\n",
    "2. The `flag` fields are populated with the ids of the related flags\n",
    "3. The two letter codes are replaced by the country ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1d07c2614c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'countries' in db_flag.list_collection_names():\n",
    "    db_flag.drop_collection('countries')\n",
    "\n",
    "cl_countries = db_flag.create_collection('countries')\n",
    "cl_countries.insert_many(country_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us display the record of South Africa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5cb36c4a351ab0b070ec8233'),\n",
       " 'code': 'ZA',\n",
       " 'data': {'name': 'SOUTH AFRICA',\n",
       "  'continent': 'AFRICA',\n",
       "  'adapted': 1994,\n",
       "  'founded': 1910,\n",
       "  'independent': 1910,\n",
       "  'neighbours': ['BW', 'LS', 'MZ', 'NA', 'SZ', 'ZW'],\n",
       "  'religion': 'CHR'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(cl_countries.find({'code' : 'ZA'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then search for all countries that became independent between 1989 an 1993. We are expecting to see states from the reorganised Eastern Block, which we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5cb36c4a351ab0b070ec819c'), 'code': 'AM'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec819f'), 'code': 'AZ'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec81a4'), 'code': 'BY'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec81aa'), 'code': 'BA'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec81bd'), 'code': 'HR'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec81c0'), 'code': 'CZ'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec81ca'), 'code': 'ER'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec81cb'), 'code': 'EE'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec81d2'), 'code': 'GE'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec81d3'), 'code': 'DE'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec81e9'), 'code': 'KZ'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec81ed'), 'code': 'KG'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec81ef'), 'code': 'LV'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec81f5'), 'code': 'LT'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec81f7'), 'code': 'MK'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec8203'), 'code': 'MD'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec820a'), 'code': 'NA'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec8221'), 'code': 'RU'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec822f'), 'code': 'SK'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec8230'), 'code': 'SI'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec823f'), 'code': 'TJ'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec8248'), 'code': 'TM'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec824b'), 'code': 'UA'}\n",
      "{'_id': ObjectId('5cb36c4a351ab0b070ec8250'), 'code': 'UZ'}\n"
     ]
    }
   ],
   "source": [
    "for country in cl_countries.find({'data.independent' : {'$gt' : 1988, '$lt' : 1994}}, {'code' : 1}):\n",
    "    print(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step the ids of the associated flag documents are inserted. Since the two letter code is included in each flag document they can easily be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flag in db_flag.flags.find():\n",
    "    db_flag.countries.update_one(\n",
    "            {'code': flag['code'] },\n",
    "            {'$set': {'flag': flag['_id']}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The each document now contains the id of the associated flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5cb36c4a351ab0b070ec8233'),\n",
       " 'code': 'ZA',\n",
       " 'data': {'name': 'SOUTH AFRICA',\n",
       "  'continent': 'AFRICA',\n",
       "  'adapted': 1994,\n",
       "  'founded': 1910,\n",
       "  'independent': 1910,\n",
       "  'neighbours': ['BW', 'LS', 'MZ', 'NA', 'SZ', 'ZW'],\n",
       "  'religion': 'CHR'},\n",
       " 'flag': ObjectId('5cb36c42351ab0b070ec816f')}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_flag.countries.find_one({'code' : 'ZA'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the two letter codes in the neighbour list are replaced by the id-s of the countries they represent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in db_flag.countries.find():\n",
    "    \n",
    "    # find ids of neighbouring countries\n",
    "    ids = [db_flag.countries.find_one({'code' : code})['_id'] for code in country['data']['neighbours']]\n",
    "     \n",
    "    # update country\n",
    "    cid = country['_id']\n",
    "    db_flag.countries.update_one(\n",
    "            {'_id' : cid}, \n",
    "            {'$set' : {'data.neighbours' : ids}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The updated field therefore lists the object ids of the neighbouring countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5cb36c4a351ab0b070ec81cf'),\n",
       " 'code': 'FR',\n",
       " 'data': {'name': 'FRANCE',\n",
       "  'continent': 'EUROPE',\n",
       "  'adapted': 1789,\n",
       "  'founded': 9999,\n",
       "  'independent': 1944,\n",
       "  'neighbours': [ObjectId('5cb36c4a351ab0b070ec824d'),\n",
       "   ObjectId('5cb36c4a351ab0b070ec8198'),\n",
       "   ObjectId('5cb36c4a351ab0b070ec81a5'),\n",
       "   ObjectId('5cb36c4a351ab0b070ec81d3'),\n",
       "   ObjectId('5cb36c4a351ab0b070ec81e5'),\n",
       "   ObjectId('5cb36c4a351ab0b070ec81f6'),\n",
       "   ObjectId('5cb36c4a351ab0b070ec8204'),\n",
       "   ObjectId('5cb36c4a351ab0b070ec8236'),\n",
       "   ObjectId('5cb36c4a351ab0b070ec823c')],\n",
       "  'religion': 'CHR'},\n",
       " 'flag': ObjectId('5cb36c42351ab0b070ec810b')}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_flag.countries.find_one({'code' : 'FR'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "A mongoDB database has been created in which attributes of countries and their flags are stored. The countries and their flags are stored in separate collection, therefore keeping the former's size small, and the latter one concise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
