{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_corpus(corpus):\n",
    "    \"\"\"\n",
    "    Extracts words from a corpus and sanitises them.\n",
    "    \"\"\"\n",
    "    \n",
    "    allowed_chars = set('abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "    \n",
    "    splitted = corpus.split()\n",
    "    \n",
    "    cleaned = (\"\".join(filter(lambda x: x in allowed_chars, word)) for word in splitted)\n",
    "    cleaned = [x.lower() for x in cleaned]\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "\n",
    "class StaticEncoder:\n",
    "\n",
    "    def __init__(self, corpus, \n",
    "                 default_missing_key = -1,\n",
    "                 default_missing_val = \"\"):\n",
    "\n",
    "        self._decoder = dict(enumerate(set(corpus)))\n",
    "\n",
    "        self._encoder = {v : k for k,v in self._decoder.items()}\n",
    "        \n",
    "        self._default_missing_key = default_missing_key\n",
    "        \n",
    "        self._default_missing_val = default_missing_val\n",
    "    \n",
    "    \n",
    "    def encode(self, x):\n",
    "        \n",
    "        return self._encoder.get(x, self._default_missing_key)\n",
    "    \n",
    "    \n",
    "    def decode(self, x):\n",
    "        \n",
    "        return self._decoder.get(x, self._default_missing_val)\n",
    "    \n",
    "train_corpus = \"\"\"\n",
    "Mary had a little lamb its fleece was white as snow;\n",
    "And everywhere that Mary went, the lamb was sure to go. \n",
    "It followed her to school one day, which was against the rule;\n",
    "It made the children laugh and play, to see a lamb at school.\n",
    "And so the teacher turned it out, but still it lingered near,\n",
    "And waited patiently about till Mary did appear.\n",
    "\"Why does the lamb love Mary so?\" the eager children cry;\n",
    "\"Why, Mary loves the lamb, you know\" the teacher did reply.\"\n",
    "\"\"\"\n",
    "\n",
    "cleaned_corpus = _clean_corpus(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_encoder = StaticEncoder(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "def _generate_all_grams(corpus):\n",
    "    \"\"\"\n",
    "    Creates a generator of all n_grams between 2, and len(corpus) -1\n",
    "    Parameters:\n",
    "        corpus ([str]) : corpus\n",
    "    \"\"\"\n",
    "    n_gram_generator = chain(*(zip(*(corpus[j:] for j in range(i))) for i in range(2, len(corpus))))\n",
    "    \n",
    "    return n_gram_generator\n",
    "\n",
    "\n",
    "def _create_n_gram_counter(n_gram_generator):\n",
    "    \"\"\"\n",
    "    Calculates the unnormalised transition matrix as a counter.\n",
    "    \"\"\"\n",
    "    \n",
    "    # split n_grams to ((n-1), 1) pairs\n",
    "    split_n_grams = ((x[:-1], x[-1]) for x in n_gram_generator)\n",
    "    \n",
    "    # count pairs\n",
    "    n_gram_counter = Counter(split_n_grams)\n",
    "\n",
    "    return n_gram_counter\n",
    "\n",
    "\n",
    "def _create_probability_dict(n_gram_counter):\n",
    "    \"\"\"\n",
    "    Calculates the transition probabilities as a dict of dicts.\n",
    "    \"\"\"\n",
    "\n",
    "    prob_dict = {}\n",
    "\n",
    "    for (head, tail), count in counter.items():\n",
    "    \n",
    "        if not head in prob_dict:\n",
    "            prob_dict.update({head : {tail : count}})\n",
    "        else:\n",
    "            prob_dict[head].update({tail : count})\n",
    "\n",
    "    ## normalise to unit probabilities\n",
    "    for head, tail_counts in prob_dict.items():\n",
    "        \n",
    "        tail_counts = {tail : count * 1.0 / sum(tail_counts.values()) \n",
    "                           for tail, count in tail_counts.items()}\n",
    "        \n",
    "        prob_dict[head] = tail_counts\n",
    "        \n",
    "    return prob_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramPredictor:\n",
    "    \n",
    "    \n",
    "    def __init__(self, prob_dict):\n",
    "        \"\"\"\n",
    "        Creates an instance of the n-gram predictor with a trained\n",
    "        transition matrix.\n",
    "        Parameters\n",
    "            prob_dict ({str : {str : float}}) : transition probabilites\n",
    "        \"\"\"\n",
    "        \n",
    "        self._prob_dict = prob_dict\n",
    "        \n",
    "    \n",
    "    def predict(self, string):\n",
    "        \"\"\"\n",
    "        Lists the predictions of the subsequent word based on an input string.\n",
    "        \"\"\"\n",
    "        \n",
    "        pattern = self._clean_input_string(string)\n",
    "        \n",
    "        probabilites = self._find_probability(pattern)\n",
    "        \n",
    "        self._print_probabilites(probabilites)\n",
    "        \n",
    "\n",
    "    def _print_probabilites(self, probabilites):\n",
    "        \"\"\"\n",
    "        Prints the search results.\n",
    "        Parameters:\n",
    "            search_result ({str:float} or None) : probabilities of the following word.\n",
    "        \"\"\"\n",
    "        \n",
    "        if probabilites is None:\n",
    "            print(\"No prediction available\")\n",
    "            \n",
    "        else:\n",
    "            sorted_ = sorted(probabilites.items(), key = lambda x: x[1], reverse = True)\n",
    "            string_components = [\"{0}: {1:.2f}\".format(word, prob) for word, prob in sorted_]\n",
    "            string = \" \".join(string_components)\n",
    "            print(string)\n",
    "        \n",
    "    \n",
    "    def _clean_input_string(self, string):\n",
    "        \"\"\"\n",
    "        Creates a tuple of the cleaned input string.\n",
    "        \"\"\"\n",
    "        \n",
    "        pattern = tuple(_clean_corpus(string))\n",
    "    \n",
    "        return pattern\n",
    "    \n",
    "        \n",
    "    def _find_probability(self, pattern):\n",
    "        \"\"\"\n",
    "        Tries to find the transition probabilites.\n",
    "        \"\"\"\n",
    "        \n",
    "        result = self._prob_dict.get(pattern, None)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_generator = _generate_all_grams(cleaned_corpus)\n",
    "n_gram_counter = _create_n_gram_counter(n_gram_generator)\n",
    "prob_dict = _create_probability_dict(n_gram_counter)\n",
    "\n",
    "\n",
    "n_gram_predictor = NGramPredictor(prob_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "little 0.50 lamb 0.50\n"
     ]
    }
   ],
   "source": [
    "n_gram_predictor.predict('a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
